<!-- We currently use <a href="http://www.artifact-eval.org/guidelines.html">the following guidelines</a> 
for packaging artifact submissions. However, we are preparing a revised version that should be available
around mid-October 2015! 
-->
 
<p>
This guide (<b>V20151015</b>) should help you describe, pack 
and submit your artifacts for a review.


It gradually evolves based on <a href="$#ck_root_page_url#$prior_ae$#ck_page_suffix#$">our past Artifact Evaluations</a>
and your feedback (see this <a href="http://www.slideshare.net/GrigoriFursin/presentation-fursin-aecgoppopp2015">presentation</a>
with an outcome of the past PPoPP/CGO'15 AE).


It should also help you prepare your artifacts 
for a possible public release, if you plan to do so
(for example as an auxiliary material in a Digital
Library or on your personal web page).


<!-------------------------------------------------------------------------------------------->
<h2>What to expect</h2>

You will need to prepare a small and relatively informal guide for reviewers 
using our <a href="$#ck_url_template_pull#$templates/ae_template_20151015.tex">AE LaTeX template</a> 
to explain what are your artifacts, how to access and 
use them, and what is the expected result (<i>we currently discuss with the 
conference chairs and ACM to let you keep this document as appendix in your 
paper if your artifact passes evaluation</i>).

At least two reviewers (or the whole community if you submit 
for <a href="http://adapt-workshop.org">ADAPT</a>) will follow your guide to replicate 
your results (for example, exact output match) or reproduce them 
(for example, slightly varying performance numbers or scalability
on a different machine), and will then send you a report with the 
following overall assessment of your artifact based 
on our <a href="$#ck_root_page_url#$reviewing$#ck_page_suffix#$">reviewing guidelines</a>:

<ul>
 <li>
  <b>significantly exceeded expectations</b>
 </li>
 <li>
  <b>exceeded expectations</b>
 </li>
 <li>
  <b>met expectations</b>
 </li>
 <li>
  <b>fell below expectations</b>
 </li>
 <li>
  <b>significantly fell below expectations</b>
 </li>
</ul>

where <b>"met expectations" score or above</b> means that your artifact 
successfully passed evaluation and will receive a stamp of approval
(added to the paper itself):

<center>
<img src="$#ck_url_template_pull#$resources/ae_logo.png">
</center>

The highest ranked artifact will also receive a <i>"distinguished artifact" 
award</i>  (see <a href="http://cTuning.org/event/ae-ppopp2015">PPoPP'15</a> 
and <a href="http://cTuning.org/event/ae-cgo2015">CGO'15</a> AE prizes)
announced at the joint CGO-PPoPP'16 AE discussion session.

This section is also used as a discussion forum with the community
about how to improve AE.

<p>
Since our eventual goal is not to name and shame
problematic artifacts, but to promote artifact
validation and sharing, you will be able to address
raised issues during the rebuttal.

Furthermore, we allow light communication between reviewers and authors 
whenever there are installation/usage problems.

In such cases, AE chairs will serve as a proxy to avoid 
revealing reviewers' identity (unless you submit artifacts 
along with your publication for an <a href="http://adapt-workshop.org">ADAPT 
workshop with a public Reddit-based evaluation</a>).

<!-------------------------------------------------------------------------------------------->
<h2>Preparing artifacts for submission</h2>

To minimize your effort, we prepared a <a href="$#ck_url_template_pull#$templates/ae_template.tex">LaTeX template</a> 
which you can fill in, append to the end of your paper, and submit the final PDF for the artifact review.

Each template subsection is described below.

If you encounter problems or have any questions, do not hesitate to 
contact <a href="mailto:childers@cs.pitt.edu;Grigori.Fursin@cTuning.org">AE chairs</a> privately
or use our public <a href="https://www.linkedin.com/grp/home?gid=7433414">LinkedIn group</a> 
and this <a href="https://groups.google.com/forum/#!forum/collective-knowledge">mailing list</a>.

<!-------------------------------------------------------------------------------------------->
<div style="margin-left: 20px;">

<!------------------------------------------------------------------->
 <h2>Abstract</h2>

<!------------------------------------------------------------------->
 <h2>Description</h2>
  <div style="margin-left: 20px;">

   <h3>Brief check-list (artifact meta-information)</h3>

     <img src="$#ck_url_template_pull#$resources/image-general-workflow1.png"><br><br>

     Make sure that reviewers have competence + possibly help find your artifacts as meta in Digital Library (under discussion/development)

   <h3>How delivered</h3>

   <h3>Hardware dependencies</h3>

   <h3>Software dependencies</h3>

   <h3>Datasets</h3>

   <h3>Interactive report</h3>
  </div>

<!------------------------------------------------------------------->
 <h2>Installation</h2>

<!------------------------------------------------------------------->
 <h2>Experiment workflow</h2>

   <img src="$#ck_url_template_pull#$resources/image-pipelines2.png"><br><br>
  

  
  Such experimental workflow should cover many cases in computer systems' research including performance analysis, 
  autotuning, benchmarking, architecture simulation,
  design space exploration, software/hardware co-design,
  run-time adaptation, machine learning, etc <sup>( <i><a href="https://hal.inria.fr/hal-01054763">example</a></i> )</sup>.

<!------------------------------------------------------------------->
 <h2>Evaluation and expected result</h2>

<!------------------------------------------------------------------->
 <h2>Notes</h2>

<!------------------------------------------------------------------->
 <h2>Own assessment</h2>

  <div style="margin-left: 20px;">

   <table border="1" cellpadding="5" cellspacing="0">
    <tr>
     <td><b>Criteria</b></td>
     <td><b>Score (readiness on scale 0..10)</b></td>
    </tr>
    <tr>
     <td>Documentation</td>
     <td></td>
    </tr>
    <tr>
     <td>Completeness</td>
     <td></td>
    </tr>
    <tr>
     <td>Installation</td>
     <td></td>
    </tr>
    <tr>
     <td>Use case</td>
     <td></td>
    </tr>
    <tr>
     <td>Expected behavior</td>
     <td></td>
    </tr>
   </table>

  </div>


</div>


<!-------------------------------------------------------------------------------------------->
<h2>Examples of accepted artifacts from past conferences, workshops and journals</h2>





<!-------------------------------------------------------------------------------------------->
<h2>Methodology archive</h2>

To help readers understand which submission/reviewing methodology was used in papers 
with evaluated artifacts we keep track of all past versions:
<ul>
 <li><b>V20151015 (PPoPP'16/CGO'16/ADAPT'16)</b>: 
  <a href="$#ck_url_template_pull#$templates/ae-20151015.tex">LaTeX template</a>,
  <a href="$#ck_root_page_url#$submission-20151015$#ck_page_suffix#$">submission guide</a>,
  <a href="$#ck_root_page_url#$reviewing-20151015$#ck_page_suffix#$">reviewing guide</a>
</ul>

<!-------------------------------------------------------------------------------------------->
<h1>If accepted</h1>

<div style="margin-left: 20px;">
 <h2>Final paper</h2>

 You will be given conference-specific instructions about how 
 to add a scalable logo "Arifact Evaluated" to your paper. 

 You can also keep AE appendix in your final paper
 (while removing all unnecessary or confidential information).

 <h2>Artifact sharing</h2>

 Though you are not obliged to publicly release your artifacts 
 (in fact, it is sometimes impossible due to various limitations), 
 we strongly encourage you to share them with the community
 (even if they are not open-source).

 You can release them as an auxiliary material in Digital Libraries,
 your institutional repository, various open services for code
 and data sharing.

 Furthermore, many of the encountered problems during AE 
 motivated us to start developing a supporting open-source technology 
 that can help improve artifact sharing, validation and reuse:
 <ul>
  <li>
   <b><a href="http://www.occamportal.org">OCCAM Framework</a></b> - enabling open curation for computer architecture modeling.
  </li>
  <li>
   <b><a href="http://github.com/ctuning/ck/wiki">Collective Knowledge Framework (CK)</a></b> - 
   converting artifacts (code and data) into reusable components and experimental workflows with Python-based wrappers and unified JSON API
   shared via <a href="http://github.com/ctuning/ck">GitHub</a> (see example of 
    <a href="https://github.com/ctuning/ck/wiki/Getting_started_guide_clsmith">PLDI'15 CLSmith artifact</a> converted to 
    <a href="https://github.com/ctuning/ck-clsmith">CK format</a>). 
  </li>
 </ul>

 You are welcome to use the following <a href="$#ck_url_template_pull#$templates/ae.html">AE HTML template</a> 
 to describe your artifact or check out our <a href="http://github.com/ctuning/ck/wiki">CK framework</a> 
 to prepare interactive reports with experiment replay (as demonstrated on <a href="http://cknowledge.org/repo/web.php?wcid=report:b0779e2a64c22907">this page 
 for CK-powered universal and multi-objective OpenCL autotuning</a>). 
</div>


